{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code based on GuitarLSTM by Keith Bloemer:\n",
    "# https://github.com/GuitarML/GuitarLSTM\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from keras import models\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import random\n",
    "\n",
    "import data\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "sr = 22050\n",
    "\n",
    "# Choose which genre to model\n",
    "genre = \"Metal\"\n",
    "\n",
    "# Size of frame (in samples) that is fed to the model during training\n",
    "frame = 64\n",
    "# Chunk == sample\n",
    "chunk = 1\n",
    "\n",
    "# Duration of data in seconds\n",
    "duration = 120\n",
    "\n",
    "# Type of input; sequential or random frame order\n",
    "sequential_input = False\n",
    "\n",
    "if sequential_input==True:\n",
    "    shuffle_state = False\n",
    "elif sequential_input==False:\n",
    "    shuffle_state = True\n",
    "\n",
    "# Model name for saving the model\n",
    "model_name_save = 'csc475_baseline_1'\n",
    "\n",
    "# If dual_layer is True then the model will have 2 layers of LSTM\n",
    "dual_layer=False\n",
    "\n",
    "# Use mu law companding\n",
    "mu_law=False\n",
    "\n",
    "# Number of hidden units in the lstm layer\n",
    "hidden_units = 16\n",
    "\n",
    "# Batch size for training\n",
    "batch_size_para = 64\n",
    "\n",
    "# Epochs during training\n",
    "epochs_ = 50\n",
    "\n",
    "# Choose which test file segment to inspect visually\n",
    "# Between 0 and 5 for default 2 minute duration\n",
    "index_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling GPU for Mac M1 chips running tensorflow metal, do not use if not on Mac with M1 chip. \n",
    "# (RNNs run slowly on GPU)\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset\n",
    "file_data_path = os.path.join(\"dataset\", \"fileData.csv\")\n",
    "effect_data_path = os.path.join(\"dataset\", \"effectData.csv\")\n",
    "\n",
    "# Loading the dry and wet audio\n",
    "signal, wet = data.create_data(genre, effect_data_path, file_data_path, mu_comp=mu_law, srate=sr, \n",
    "                               duration=duration, type=\"random\")\n",
    "\n",
    "# Size of frames in training dataset\n",
    "training_dataset_ = (int) ((len(signal) / frame) * 0.8)\n",
    "\n",
    "# Size of frames for testing (not the proper testset, details below)\n",
    "testing_dataset_ = (int) ((len(signal) / frame) * 0.2)\n",
    "\n",
    "# Wether to filter the audio\n",
    "filtered = False\n",
    "\n",
    "# Creating a high pass filter \n",
    "\n",
    "numtaps = 91\n",
    "cutoff = 0.015\n",
    "b = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='highpass')\n",
    "\n",
    "# Creating a lowpass filter\n",
    "\n",
    "numtaps = 41\n",
    "cutoff = 0.92\n",
    "\n",
    "b2 = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='lowpass')\n",
    "\n",
    "# Optionally high pass audio to emphasize high frequency information, low pass to avoid aliasing artifacts\n",
    "if filtered is True:\n",
    "    # High Pass Filter\n",
    "    signal = scipy.signal.lfilter(b, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b, 1, wet)\n",
    "    # Low Pass Filter\n",
    "    signal = scipy.signal.lfilter(b2, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b2, 1, wet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing the original dry audio to the wet audio as a reference' )\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(signal, wet))\n",
    "print('Mean squared error: %.4f'% metrics.mean_squared_error(signal, wet))\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(signal, wet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_file, output_file, size_training, size_test, frame, sr=sr):\n",
    "    \n",
    "    signal = input_file\n",
    "    wet = output_file\n",
    "    \n",
    "    # Creating the foundation of the dataset by splitting the whole audio into 5 seconds segments\n",
    "    segment_size = sr * 5\n",
    "    dry_segments = np.zeros((int(signal.size/segment_size), segment_size))\n",
    "    wet_segments = np.zeros((int(signal.size/segment_size), segment_size))\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(0, signal.size-segment_size-1, segment_size):\n",
    "                \n",
    "        dry_segment = signal[i:i+segment_size]\n",
    "        \n",
    "        wet_segment = wet[i:i+segment_size]\n",
    "\n",
    "        dry_segments[counter,:], wet_segments[counter,:] = dry_segment, wet_segment\n",
    "        counter+= 1\n",
    "\n",
    "    # Splitting the segments into the training and testing set\n",
    "    dry_train, dry_test, wet_train, wet_test = train_test_split(dry_segments, wet_segments, test_size=0.2, random_state=5)\n",
    "\n",
    "\n",
    "    # Creating the training set (randomly pulling frames and target value from all segments in train set)\n",
    "\n",
    "    features_train = np.zeros((size_training, frame))\n",
    "    targets_train = np.zeros((size_training))\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(size_training):\n",
    "        random_index = random.randint(0,dry_train.shape[0]-1)\n",
    "        dry_slice = dry_train[random_index]\n",
    "        wet_slice = wet_train[random_index]\n",
    "        random_start = random.randint(0,segment_size-frame-2)\n",
    "        features = dry_slice[random_start:random_start+frame]\n",
    "        target = wet_slice[random_start+frame-1]\n",
    "        features_train[counter,:], targets_train[counter] = features, target\n",
    "        counter += 1\n",
    "\n",
    "    # Creating the testing set (randomly puling frames and target value from segments in test set)\n",
    "\n",
    "    features_test = np.zeros((size_test, frame))\n",
    "    targets_test = np.zeros((size_test))\n",
    "    counter = 0\n",
    "    for i in range(size_test):\n",
    "        random_index = random.randint(0,dry_test.shape[0]-1)\n",
    "        dry_slice = dry_test[random_index]\n",
    "        wet_slice = wet_test[random_index]\n",
    "        random_start = random.randint(0,segment_size-frame-2)\n",
    "        features = dry_slice[random_start:random_start+frame]\n",
    "        target = wet_slice[random_start+frame-1]\n",
    "        features_test[counter,:], targets_test[counter] = features, target\n",
    "        counter += 1\n",
    "\n",
    "    return dry_test, wet_test, features_train, features_test, targets_train, targets_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequential_dataset(input_file, output_file, size_training, size_test, frame, sr=sr):\n",
    "    \n",
    "    signal = input_file\n",
    "    wet = output_file\n",
    "    \n",
    "    # Creating the foundation of the dataset by splitting the whole audio into 5 seconds segments\n",
    "    segment_size = sr * 5\n",
    "    dry_segments = np.zeros((int(signal.size/segment_size), segment_size))\n",
    "    wet_segments = np.zeros((int(signal.size/segment_size), segment_size))\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(0, signal.size-segment_size-1, segment_size):\n",
    "                \n",
    "        dry_segment = signal[i:i+segment_size]\n",
    "        \n",
    "        wet_segment = wet[i:i+segment_size]\n",
    "\n",
    "        dry_segments[counter,:], wet_segments[counter,:] = dry_segment, wet_segment\n",
    "        counter+= 1\n",
    "\n",
    "    # Splitting the segments into the training and testing set\n",
    "    dry_train, dry_test, wet_train, wet_test = train_test_split(dry_segments, wet_segments, test_size=0.2, random_state=5)\n",
    "\n",
    "    \n",
    "    # Creating the training set (pulling frames in sequence from training and testing segments)\n",
    "    train_frames_pr_segment = int(size_training / dry_train.shape[0])\n",
    "    test_frames_pr_segment = int(size_test / dry_test.shape[0])\n",
    "\n",
    "    features_train = np.zeros((size_training, frame))\n",
    "    targets_train = np.zeros((size_training))\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(0,dry_train.shape[0]):\n",
    "        dry_segment = dry_train[i]\n",
    "        wet_segment = wet_train[i]\n",
    "        random_start = random.randint(0,dry_segment.size-train_frames_pr_segment-frame-1)\n",
    "        for x in range(0+frame, train_frames_pr_segment+frame-2):\n",
    "            start_point = x + random_start      \n",
    "            features = dry_segment[start_point:start_point+frame]\n",
    "            target = wet_segment[start_point+frame-1]\n",
    "            \n",
    "            features_train[counter,:], targets_train[counter] = features, target\n",
    "            counter+= 1\n",
    "\n",
    "    # Creating the testing set (sequentiually pulling frames and target value from segments in test set)\n",
    "    features_test = np.zeros((size_test, frame))\n",
    "    targets_test = np.zeros((size_test))\n",
    "    counter = 0\n",
    "    for i in range(0,dry_test.shape[0]):\n",
    "        dry_segment = dry_test[i]\n",
    "        wet_segment = wet_test[i]\n",
    "        random_start = random.randint(0,dry_segment.size-test_frames_pr_segment-frame-1)\n",
    "        \n",
    "        for x in range(0+frame, test_frames_pr_segment+frame-1):\n",
    "            start_point = x + random_start      \n",
    "            features = dry_segment[start_point:start_point+frame]\n",
    "            target = wet_segment[start_point+frame-1]\n",
    "            \n",
    "            features_test[counter,:], targets_test[counter] = features, target\n",
    "            counter+= 1 \n",
    "            \n",
    "    return dry_test, wet_test, features_train, features_test, targets_train, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing the create_dataset function\n",
    "if sequential_input==False:\n",
    "    dry_test, wet_test, features_train, features_test, targets_train, targets_test = create_dataset(signal, wet, training_dataset_, testing_dataset_, frame)\n",
    "elif sequential_input==True:\n",
    "    dry_test, wet_test, features_train, features_test, targets_train, targets_test = create_sequential_dataset(signal, wet, training_dataset_, testing_dataset_, frame)\n",
    "\n",
    "length_in_seconds = features_train.size / sr\n",
    "length_for_wet = targets_train.size / sr\n",
    "print('Length of training dry audio is {} seconds'.format(length_in_seconds)) \n",
    "print('Length of training wet audio is {} seconds'.format(length_for_wet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions used later in the notebook'''\n",
    "def myFIRFiltResponse(b,title, sr, a=1): \n",
    "    #sns.set_theme()\n",
    "    w, h = scipy.signal.freqz(b,a)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_title(title)\n",
    "    ax1.plot((w/math.pi)*sr, np.log10(np.abs(h)), 'b')\n",
    "    ax1.set_ylabel('Amplitude [dB]', color='b')\n",
    "    ax1.set_xlabel('Normalized Frequency')\n",
    "    ax2 = ax1.twinx()\n",
    "    angles = np.unwrap(np.angle(h))\n",
    "    ax2.plot(w/math.pi, angles, 'g')\n",
    "    ax2.set_ylabel('Angle (radians)', color='g')\n",
    "    ax2.grid()\n",
    "    ax2.axis('tight')\n",
    "    plt.show()\n",
    "\n",
    "def prepare_audio(filename, sr, dur, offset):\n",
    "    audio, dummy = librosa.load(filename, sr=sr, mono=True, duration=dur, offset=offset )\n",
    "    counter = 0\n",
    "    \n",
    "    audio = np.pad(audio, (frame-1,0))\n",
    "    \n",
    "    results = np.zeros((audio.size, frame))\n",
    "    for i in range(0+frame,audio.size-frame-1):\n",
    "        \n",
    "            segment = audio[i-frame:i]\n",
    "            \n",
    "\n",
    "            results[counter,:] = segment\n",
    "            counter+= 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def prepare_audio_seq(dry_test, index):\n",
    "    '''Function to prepare audio for the model to predict, as the model expects \n",
    "    the input of sequentially ordered frames.'''\n",
    "    audio = dry_test[index]\n",
    "    counter = 0\n",
    "    audio = np.pad(audio, (frame-1,0))\n",
    "    audio = audio[0:audio.size-frame+1]\n",
    "    results = np.zeros((audio.size, frame))\n",
    "    for i in range(0+frame,audio.size-frame-1):\n",
    "        \n",
    "            segment = audio[i-frame:i]\n",
    "            results[counter,:] = segment\n",
    "            counter+= 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def mySpectrogram(s,sr,title):\n",
    "    #sns.set_theme()\n",
    "    D = librosa.stft(s)\n",
    "    DdB = librosa.amplitude_to_db(abs(D))\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    librosa.display.specshow(DdB, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def myWaveform(s,title):\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    plt.plot(s)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def compare_waveforms(original, predicted, true_output, title, start,stop):\n",
    "    '''Simple function to plot three waveforms for comparing'''\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.plot(original[start:stop])\n",
    "    plt.plot(predicted[start:stop])\n",
    "    plt.plot(true_output[start:stop])\n",
    "    plt.legend(['original', 'predicted', 'true output'])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line clears the memory of the model being used in the notebook enabling quick experiments without changing\n",
    "# the name of the model. \n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Creating the model with either one or two layers based on the dual_layer Boolean value. \n",
    "model = tf.keras.Sequential(name=model_name_save)\n",
    "    \n",
    "model.add(tf.keras.layers.Input(shape=(frame, chunk)))\n",
    "    \n",
    "if dual_layer==True:    \n",
    "    model.add(tf.keras.layers.LSTM(hidden_units, activation='tanh', return_sequences=True, name='layer1'+model_name_save))\n",
    "    model.add(tf.keras.layers.LSTM(hidden_units, activation='tanh', return_sequences=False, name= 'layer2'+model_name_save))\n",
    "else:\n",
    "    model.add(tf.keras.layers.LSTM(hidden_units, activation='tanh', return_sequences=False, name='layer'+model_name_save))\n",
    "    \n",
    "model.add(tf.keras.layers.Dense(1)) \n",
    " \n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "TIP: Try with a model using a dataset of 40000 frames and 50 epochs to shorten the training time. Results should still be ok. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    features_train,\n",
    "    targets_train,\n",
    "    \n",
    "    batch_size=batch_size_para,\n",
    "    shuffle=False,\n",
    "    epochs=epochs_,\n",
    "    callbacks = [callback_stop],\n",
    "    validation_split = 0.15,\n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_pred = model.predict(features_test)\n",
    "train_tar_pred = model.predict(features_train)\n",
    "\n",
    "# Evaluating the training process\n",
    "\n",
    "#mean squared error (lower the better)\n",
    "print('Mean squared error: {}'.format(metrics.mean_squared_error(targets_test, tar_pred)))\n",
    "\n",
    "#mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(targets_test, tar_pred))\n",
    "\n",
    "#median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% metrics.median_absolute_error(targets_test, tar_pred))\n",
    "\n",
    "#coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(targets_test, tar_pred))\n",
    "\n",
    "#explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% metrics.explained_variance_score(targets_test, tar_pred))\n",
    "\n",
    "def plot_result(trainY, testY, train_predict, test_predict):\n",
    "    actual = np.append(trainY, testY)\n",
    "    predictions = np.append(train_predict, test_predict)\n",
    "    rows = len(actual)\n",
    "    plt.figure(figsize=(15, 6), dpi=80)\n",
    "    plt.plot(range(rows), actual, alpha=0.3, color='blue')\n",
    "    plt.plot(range(rows), predictions, alpha=0.3, color='green')\n",
    "    plt.axvline(x=len(trainY), color='r')\n",
    "    plt.legend(['Actual', 'Predictions'])\n",
    "    plt.xlabel('Time in samples')\n",
    "    plt.ylabel('')\n",
    "    plt.title('Actual and Predicted Values. The Red Line Separates The Training And Test Examples')\n",
    "    \n",
    "plot_result(targets_train, targets_test, train_tar_pred, tar_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model (ignore warnings)\n",
    "model.save(os.path.join('dataset', 'models',model_name_save + '.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=index_number\n",
    "\n",
    "start = time.time()\n",
    "prepared_audio = prepare_audio_seq(dry_test, index=index)\n",
    "testfile = model.predict(prepared_audio)\n",
    "#testfile = loaded_model.predict(prepared_audio)\n",
    "testfile = testfile.flatten()\n",
    "\n",
    "stop = time.time()\n",
    "inference = stop - start \n",
    "print('Inference of 5 Seconds of audio took {} seconds with a samplerate of {}'.format(inference, sr))\n",
    "\n",
    "original = dry_test[index]\n",
    "original_wet = wet_test[index]\n",
    "\n",
    "if mu_law == True:\n",
    "    original = librosa.mu_expand(dry_test[index])\n",
    "    testfile = np.round(testfile)\n",
    "    testfile = librosa.mu_expand(testfile)\n",
    "    original_wet = librosa.mu_expand(wet_test[index])\n",
    "\n",
    "myWaveform(original, 'Input')\n",
    "ipd.display(ipd.Audio(original, rate=sr))\n",
    "\n",
    "myWaveform(testfile, 'Predicted Output')\n",
    "ipd.display(ipd.Audio(testfile, rate=sr))\n",
    "\n",
    "myWaveform(original_wet, 'Correct Output')\n",
    "ipd.display(ipd.Audio(original_wet, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing short segments of the waveforms of the dry audio, predicted audio and the target wet audio\n",
    "compare_waveforms(\n",
    "    original, \n",
    "    testfile, \n",
    "    original_wet, \n",
    "    model_name_save + ' ' + genre, \n",
    "    10000, \n",
    "    10200\n",
    "    )\n",
    "\n",
    "compare_waveforms(\n",
    "    original, \n",
    "    testfile, \n",
    "    original_wet, \n",
    "    model_name_save + ' ' + genre, \n",
    "    40000, \n",
    "    40200\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing spectrograms set to showing hz with no mel or log scale, to inspect high frequencies.\n",
    "def mySpectrogram_hz(s,sr,title, style):\n",
    "    #sns.set_theme()\n",
    "    D = librosa.stft(s)\n",
    "    DdB = librosa.amplitude_to_db(abs(D))\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    librosa.display.specshow(DdB[0:1800], sr=sr, x_axis='time', y_axis=style)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "mySpectrogram_hz(original, sr, 'Input ' + model_name_save, 'hz')\n",
    "mySpectrogram_hz(original_wet, sr, 'Original Output ' + model_name_save + ' ' + genre, 'hz')\n",
    "mySpectrogram_hz(testfile, sr, 'Predicted Output ' + model_name_save + ' ' + genre, 'hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_description(model):\n",
    "    print(model.summary())\n",
    "    print(model_name_save)\n",
    "    print('The effect modeled: {}'.format(genre))\n",
    "    print('Size of input audio frame is {}'.format(frame))\n",
    "    print('Total length of audio in training dataset: {} seconds'.format(features_train.size / sr))\n",
    "    print('Total number of frames in the training set: {}'.format(features_train.shape[0]))\n",
    "    print('Number of epochs: {}'.format(epochs_))\n",
    "    print('Batch size during training: {}'.format(batch_size_para))\n",
    "    print('Sequential input: {}'.format(sequential_input))\n",
    "\n",
    "def energy_normalized_mae(true, predicted):\n",
    "    y_true = true / np.max(true)\n",
    "    y_pred = predicted / np.max(predicted)\n",
    "    return metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def ESR(true, predicted):\n",
    "    return np.sum(np.square(np.abs(true-predicted))) / np.sum(np.square(np.abs(true)))\n",
    "\n",
    "def normalized_ESR(true, predicted):\n",
    "    true = true / np.max(true)\n",
    "    predicted = predicted/np.max(predicted)\n",
    "    return np.sum(np.square(np.abs(true-predicted))) / np.sum(np.square(np.abs(true)))\n",
    "\n",
    "def avg_metrics_on_predictions(k_fold=5, randomized=False):\n",
    "    '''Function to compute metrics on multiple segments of the test set. k_fold determines how many\n",
    "    segments are analysed. If random is set to false, it will compute metrics for index number 0 to k_fold,\n",
    "    enabling the user to compute metrics for the whole test set if k_fold is set to dry_shape[0].\n",
    "    Else if random is True then the function will randomly pick k_fold number of segments from the test set.'''\n",
    "    import random\n",
    "    \n",
    "    predicted = np.zeros((dry_test.shape[0],dry_test.shape[1]))\n",
    "    original_wet = np.zeros((dry_test.shape[0],dry_test.shape[1]))\n",
    "    r2 = np.array([])\n",
    "    mae = np.array([])\n",
    "    timer = 0\n",
    "    for i in range(k_fold):\n",
    "        if randomized==False:\n",
    "            start = time.time()\n",
    "            to_predict = prepare_audio_seq(dry_test, i)\n",
    "            prediction = model.predict(to_predict)\n",
    "            prediction = prediction.flatten()\n",
    "            stop = time.time()\n",
    "            timer += (stop-start)\n",
    "\n",
    "            predicted[i]= prediction\n",
    "            original_wet[i] = wet_test[i]\n",
    "\n",
    "            r2 = np.append(r2, metrics.r2_score(original_wet[i], predicted[i]))\n",
    "            mae = np.append(mae, metrics.mean_absolute_error(original_wet[i], predicted[i]))\n",
    "\n",
    "        elif randomized==True:\n",
    "            random_choice = random.randint(0,k_fold)\n",
    "            start = time.time()\n",
    "            to_predict = prepare_audio_seq(dry_test, random_choice)\n",
    "            prediction = model.predict(to_predict)\n",
    "            prediction = prediction.flatten()\n",
    "            stop = time.time()\n",
    "            timer += (stop-start)\n",
    "\n",
    "            predicted[i]= prediction\n",
    "            original_wet[i] = wet_test[random_choice]\n",
    "\n",
    "            r2 = np.append(r2, metrics.r2_score(original_wet[i], predicted[i]))\n",
    "            mae = np.append(mae, metrics.mean_absolute_error(original_wet[i], predicted[i]))\n",
    "\n",
    "    print('The model: {}'.format(model_description(model)))\n",
    "\n",
    "\n",
    "    print('R2 individual scores for segments is {}'.format(r2))\n",
    "    print('Mae individual scores for segments is {}'.format(mae))\n",
    "\n",
    "    print('Overall average metrics for original wet audio vs predicted on test set:' )\n",
    "    #mean absolute error (lower the better)\n",
    "    MAE_ = metrics.mean_absolute_error(original_wet, predicted)\n",
    "    R2_ = metrics.r2_score(original_wet, predicted)\n",
    "    EN_MAE_ = energy_normalized_mae(original_wet, predicted)\n",
    "    ESR_ = ESR(original_wet, predicted)\n",
    "    print('Energy Normalized Mae: {}'.format(EN_MAE_))\n",
    "    print('Mae: {}'.format(MAE_))\n",
    "    print('R2: {}'.format(R2_) )\n",
    "    print('ESR: {}'.format(ESR_))\n",
    "\n",
    "    print('Inference time for {} seconds of audio was {} seconds'.format((dry_test.size/sr),(timer)))\n",
    "    inference_time = timer / (dry_test.size/sr)\n",
    "\n",
    "    return MAE_, R2_, EN_MAE_, ESR_, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the whole test set and returning the mae, r2 and energy normalized mae, as well as \n",
    "MAE_, R2_, EN_MAE_, ESR_, inference_time = avg_metrics_on_predictions(k_fold=dry_test.shape[0], randomized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = os.path.join('dataset', 'experiments')\n",
    "\n",
    "sf.write(os.path.join(experiments_path, model_name_save + genre +'.wav'), testfile, sr)\n",
    "sf.write(os.path.join(experiments_path, genre +  str(index) + '.wav'), original_wet, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(experiments_path, 'experiments-'+ genre + '.csv') \n",
    "\n",
    "if (os.path.isfile(csv_path)):\n",
    "    dataset = pd.read_csv(csv_path, header=None)\n",
    "else:\n",
    "    dataset = pd.DataFrame(columns=[\n",
    "        'Model Name', 'Effect', 'Frame', 'Sequential Input', 'Training Dataset', \n",
    "        'Hidden Units', 'Batch Size', 'Epochs', 'MAE', 'R2', 'Inference Time',\n",
    "        'EN MAE'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a row to the dataframe\n",
    "s_row = pd.Series([\n",
    "    model_name_save,genre,frame,sequential_input,training_dataset_, hidden_units, \n",
    "    batch_size_para, epochs_, MAE_, R2_, inference_time, EN_MAE_\n",
    "], index=dataset.columns)\n",
    " \n",
    "# Append the above pandas Series object as a row to the existing pandas DataFrame\n",
    "dataset.loc[len(dataset)] = s_row\n",
    "\n",
    "# Displaying the dataframe\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the updated dataframe back to the csv file.\n",
    "if (os.path.isfile(csv_path)):\n",
    "    dataset.to_csv(csv_path, header=False, index=False)\n",
    "else:\n",
    "    dataset.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pentatonic scale for demo\n",
    "# Keep running till first 5 seconds sound decent\n",
    "clean, effect = data.create_data(genre, effect_data_path, file_data_path, mu_comp=mu_law, srate=sr, \n",
    "                               duration=15, type=\"pentatonic\")\n",
    "\n",
    "length = (int) (len(clean) / frame)\n",
    "\n",
    "ipd.display(ipd.Audio(clean, rate=sr))\n",
    "\n",
    "clean_test, effect_test, _, features_test, _, targets_test = create_dataset(clean, effect, 0, length, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict audio with model and save files for later use\n",
    "prepared_audio = prepare_audio_seq(clean_test, index=0)\n",
    "\n",
    "predicted = model.predict(prepared_audio)\n",
    "\n",
    "predicted = predicted.flatten()\n",
    "\n",
    "ipd.display(ipd.Audio(predicted, rate=sr))\n",
    "ipd.display(ipd.Audio(effect_test[0], rate=sr))\n",
    "\n",
    "sf.write(os.path.join(experiments_path, 'Predicted_Demo.wav'), predicted, sr)\n",
    "sf.write(os.path.join(experiments_path, 'Effect_Demo.wav'), effect_test[0], sr)\n",
    "sf.write(os.path.join(experiments_path, 'Clean_Demo.wav'), clean_test[0], sr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "446f2e837f7725be6334aa8de739a626b7e93b99618fed198ab63865836f8ce5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
