{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import random\n",
    "\n",
    "import data\n",
    "import model_utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "sr = 22050\n",
    "\n",
    "# Choose which genre to model\n",
    "genre = \"Metal\"\n",
    "\n",
    "# Size of frame (in samples) that is fed to the model during training\n",
    "frame = 64\n",
    "\n",
    "# Chunk == sample\n",
    "chunk = 1\n",
    "\n",
    "# Duration of data in seconds\n",
    "duration = 30\n",
    "\n",
    "# Model name for saving the model\n",
    "model_name_save = 'csc475_gan_baseline'\n",
    "\n",
    "# Use saved data in dataset/experiments folder\n",
    "use_saved_data = False\n",
    "\n",
    "# Type of input; sequential or random frame order\n",
    "sequential_input = False\n",
    "\n",
    "if sequential_input==True:\n",
    "    shuffle_state = False\n",
    "elif sequential_input==False:\n",
    "    shuffle_state = True\n",
    "\n",
    "# Ratio of test data to training data\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Use mu law companding\n",
    "mu_law=False\n",
    "\n",
    "# Batch size for training\n",
    "batch_size_para = 64\n",
    "\n",
    "# Epochs during training\n",
    "epochs_ = 50\n",
    "\n",
    "# Choose which test file segment to inspect visually\n",
    "# Between 0 and 5 for default 2 minute duration\n",
    "index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling GPU for Mac M1 chips running tensorflow metal, do not use if not on Mac with M1 chip. \n",
    "# (RNNs run slowly on GPU)\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset\n",
    "file_data_path = os.path.join(\"dataset\", \"fileData.csv\")\n",
    "effect_data_path = os.path.join(\"dataset\", \"effectData.csv\")\n",
    "\n",
    "# Loading the dry and wet audio\n",
    "clean_audio_path = os.path.join(\"dataset\", \"experiments\", \"clean_data.wav\")\n",
    "effect_audio_path = os.path.join(\"dataset\", \"experiments\", \"effect_data.wav\")\n",
    "\n",
    "if (use_saved_data == False):\n",
    "    signal, wet = data.create_data(genre, effect_data_path, file_data_path, mu_comp=mu_law, srate=sr, \n",
    "                                   duration=duration, type=\"random\")\n",
    "    scipy.io.wavfile.write(clean_audio_path, rate=sr, data=signal)\n",
    "    scipy.io.wavfile.write(effect_audio_path, rate=sr, data=wet)\n",
    "else:\n",
    "    signal, _ = librosa.load(clean_audio_path, sr=sr)\n",
    "    wet, _ = librosa.load(effect_audio_path, sr=sr)\n",
    "    \n",
    "\n",
    "# Size of frames in training dataset\n",
    "training_dataset_ = (int) ((len(signal) / frame) * (1 - test_ratio))\n",
    "\n",
    "# Size of frames for testing (not the proper testset, details below)\n",
    "testing_dataset_ = (int) ((len(signal) / frame) * test_ratio)\n",
    "\n",
    "# Whether to filter the audio\n",
    "filtered = False\n",
    "\n",
    "# Creating a high pass filter\n",
    "numtaps = 91\n",
    "cutoff = 0.015\n",
    "b = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='highpass')\n",
    "\n",
    "# Creating a lowpass filter\n",
    "numtaps = 41\n",
    "cutoff = 0.92\n",
    "\n",
    "b2 = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='lowpass')\n",
    "\n",
    "# Optionally high pass audio to emphasize high frequency information, low pass to avoid aliasing artifacts\n",
    "if filtered is True:\n",
    "    # High Pass Filter\n",
    "    signal = scipy.signal.lfilter(b, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b, 1, wet)\n",
    "    # Low Pass Filter\n",
    "    signal = scipy.signal.lfilter(b2, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b2, 1, wet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing the original dry audio to the wet audio as a reference' )\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(signal, wet))\n",
    "print('Mean squared error: %.4f'% metrics.mean_squared_error(signal, wet))\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(signal, wet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = (int) (len(signal) * (1 - test_ratio))\n",
    "test_length = (int) (len(signal) * test_ratio)\n",
    "\n",
    "features_train = signal[0:train_length]\n",
    "features_test = signal[train_length:train_length + test_length]\n",
    "\n",
    "targets_train = wet[0:train_length]\n",
    "targets_test = wet[train_length:train_length + test_length]\n",
    "\n",
    "length_in_seconds = features_train.size / sr\n",
    "length_for_wet = targets_train.size / sr\n",
    "print('Length of training dry audio is {} seconds'.format(length_in_seconds)) \n",
    "print('Length of training wet audio is {} seconds'.format(length_for_wet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN architecture\n",
    "class Generator(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(frame * chunk, activation='tanh')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "class Discriminator(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "# Initialize generator, discriminator, and GAN\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "model = tf.keras.Sequential([generator, discriminator], name=model_name_save)\n",
    "\n",
    "# Define loss functions\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "def generate_noise(batch_size, noise_dim):\n",
    "    return tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "@tf.function\n",
    "def train_step(audio, effects):\n",
    "    noise = generate_noise(tf.shape(audio)[0], noise_dim)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_audio = generator(tf.concat([noise, effects], axis=1), training=True)\n",
    "\n",
    "        real_output = discriminator(tf.concat([audio, effects], axis=1), training=True)\n",
    "        fake_output = discriminator(tf.concat([generated_audio, effects], axis=1), training=True)\n",
    "\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        disc_loss_real = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        disc_loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Define function to apply effect to audio\n",
    "def apply_effect(audio, effect):\n",
    "    noise = generate_noise(1, noise_dim)\n",
    "    generated_audio = generator(tf.concat([noise, effect], axis=1), training=False)\n",
    "    return generated_audio.numpy()[0]\n",
    "\n",
    "# train GAN\n",
    "def train_gan(audio, effects, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        start = time.time()\n",
    "        counter = 0\n",
    "        \n",
    "        for i in range(0, len(audio), batch_size):\n",
    "            batch_audio = []\n",
    "            batch_effects = []\n",
    "            \n",
    "            if (audio[i:i+batch_size].size == batch_size and effects[i:i+batch_size].size == batch_size):\n",
    "                batch_audio.append(audio[i:i+batch_size])\n",
    "                batch_effects.append(effects[i:i+batch_size])\n",
    "\n",
    "                train_step(batch_audio, batch_effects)\n",
    "                counter += 1\n",
    "                print('Batch {} / {}'.format(counter, (int) (len(audio) / batch_size)), end='\\r')\n",
    "                \n",
    "                \n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "train_gan(features_train, targets_train, epochs=epochs_, batch_size=batch_size_para)\n",
    "\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_pred = apply_effect(features_test, targets_test)\n",
    "train_tar_pred = apply_effect(features_train, targets_train)\n",
    "\n",
    "# Mean squared error (lower the better)\n",
    "print('Mean squared error: {}'.format(metrics.mean_squared_error(targets_test, tar_pred)))\n",
    "\n",
    "# Mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(targets_test, tar_pred))\n",
    "\n",
    "# Median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% metrics.median_absolute_error(targets_test, tar_pred))\n",
    "\n",
    "# Coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(targets_test, tar_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% metrics.explained_variance_score(targets_test, tar_pred))\n",
    "    \n",
    "model_utils.plot_result(targets_train, targets_test, train_tar_pred, tar_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model (ignore warnings)\n",
    "model.save(os.path.join('dataset', 'models',model_name_save + '.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "prepared_audio = model_utils.prepare_audio_seq(dry_test, index=index, frame=frame)\n",
    "testfile = model.predict(prepared_audio)\n",
    "testfile = testfile.flatten()\n",
    "\n",
    "stop = time.time()\n",
    "\n",
    "inference = stop - start \n",
    "print('Inference of 5 Seconds of audio took {} seconds with a samplerate of {}'.format(inference, sr))\n",
    "\n",
    "original = dry_test[index]\n",
    "original_wet = wet_test[index]\n",
    "\n",
    "if mu_law == True:\n",
    "    original = librosa.mu_expand(dry_test[index])\n",
    "    testfile = np.round(testfile)\n",
    "    testfile = librosa.mu_expand(testfile)\n",
    "    original_wet = librosa.mu_expand(wet_test[index])\n",
    "\n",
    "model_utils.plot_waveform(original, 'Input')\n",
    "ipd.display(ipd.Audio(original, rate=sr))\n",
    "\n",
    "model_utils.plot_waveform(testfile, 'Predicted Output')\n",
    "ipd.display(ipd.Audio(testfile, rate=sr))\n",
    "\n",
    "model_utils.plot_waveform(original_wet, 'Correct Output')\n",
    "ipd.display(ipd.Audio(original_wet, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing short segments of the waveforms of the dry audio, predicted audio and the target wet audio\n",
    "model_utils.compare_waveforms(\n",
    "    original, \n",
    "    testfile, \n",
    "    original_wet, \n",
    "    model_name_save + ' ' + genre, \n",
    "    10000, \n",
    "    10200\n",
    ")\n",
    "model_utils.compare_waveforms(\n",
    "    original, \n",
    "    testfile, \n",
    "    original_wet, \n",
    "    model_name_save + ' ' + genre, \n",
    "    40000, \n",
    "    40200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_spectrogram_hz(original, sr, 'Input ' + model_name_save, 'hz')\n",
    "model_utils.plot_spectrogram_hz(original_wet, sr, 'Original Output ' + model_name_save + ' ' + genre, 'hz')\n",
    "model_utils.plot_spectrogram_hz(testfile, sr, 'Predicted Output ' + model_name_save + ' ' + genre, 'hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_description(model):\n",
    "    print(model.summary())\n",
    "    print(model_name_save)\n",
    "    print('The effect modeled: {}'.format(genre))\n",
    "    print('Size of input audio frame is {}'.format(frame))\n",
    "    print('Total length of audio in training dataset: {} seconds'.format(features_train.size / sr))\n",
    "    print('Total number of frames in the training set: {}'.format(features_train.shape[0]))\n",
    "    print('Number of epochs: {}'.format(epochs_))\n",
    "    print('Batch size during training: {}'.format(batch_size_para))\n",
    "    print('Sequential input: {}'.format(sequential_input))\n",
    "\n",
    "# Function to compute metrics on multiple segments of the test set. k_fold determines how many\n",
    "# segments are analysed. If random is set to false, it will compute metrics for index number 0 to k_fold,\n",
    "# enabling the user to compute metrics for the whole test set if k_fold is set to dry_shape[0].\n",
    "# Else if random is True then the function will randomly pick k_fold number of segments from the test set.\n",
    "def avg_metrics_on_predictions(k_fold=5, randomized=False):\n",
    "    predicted = np.zeros((dry_test.shape[0],dry_test.shape[1]))\n",
    "    original_wet = np.zeros((dry_test.shape[0],dry_test.shape[1]))\n",
    "    r2 = np.array([])\n",
    "    mae = np.array([])\n",
    "    timer = 0\n",
    "    \n",
    "    for i in range(k_fold):\n",
    "        if randomized==False:\n",
    "            start = time.time()\n",
    "            to_predict = model_utils.prepare_audio_seq(dry_test, i, frame=frame)\n",
    "            prediction = model.predict(to_predict)\n",
    "            prediction = prediction.flatten()\n",
    "            stop = time.time()\n",
    "            timer += (stop-start)\n",
    "\n",
    "            predicted[i]= prediction\n",
    "            original_wet[i] = wet_test[i]\n",
    "\n",
    "            r2 = np.append(r2, metrics.r2_score(original_wet[i], predicted[i]))\n",
    "            mae = np.append(mae, metrics.mean_absolute_error(original_wet[i], predicted[i]))\n",
    "\n",
    "        elif randomized==True:\n",
    "            random_choice = random.randint(0,k_fold)\n",
    "            start = time.time()\n",
    "            to_predict = model_utils.prepare_audio_seq(dry_test, random_choice, frame=frame)\n",
    "            prediction = model.predict(to_predict)\n",
    "            prediction = prediction.flatten()\n",
    "            stop = time.time()\n",
    "            timer += (stop-start)\n",
    "\n",
    "            predicted[i]= prediction\n",
    "            original_wet[i] = wet_test[random_choice]\n",
    "\n",
    "            r2 = np.append(r2, metrics.r2_score(original_wet[i], predicted[i]))\n",
    "            mae = np.append(mae, metrics.mean_absolute_error(original_wet[i], predicted[i]))\n",
    "\n",
    "    print('The model: {}'.format(model_description(model)))\n",
    "    print('R2 individual scores for segments is {}'.format(r2))\n",
    "    print('Mae individual scores for segments is {}'.format(mae))\n",
    "    print('Overall average metrics for original wet audio vs predicted on test set:' )\n",
    "\n",
    "    MAE_ = metrics.mean_absolute_error(original_wet, predicted)\n",
    "    R2_ = metrics.r2_score(original_wet, predicted)\n",
    "    EN_MAE_ = model_utils.energy_normalized_mae(original_wet, predicted)\n",
    "    ESR_ = model_utils.esr(original_wet, predicted)\n",
    "    \n",
    "    print('Energy Normalized Mae: {}'.format(EN_MAE_))\n",
    "    print('Mae: {}'.format(MAE_))\n",
    "    print('R2: {}'.format(R2_) )\n",
    "    print('ESR: {}'.format(ESR_))\n",
    "    print('Inference time for {} seconds of audio was {} seconds'.format((dry_test.size/sr),(timer)))\n",
    "    inference_time = timer / (dry_test.size/sr)\n",
    "\n",
    "    return MAE_, R2_, EN_MAE_, ESR_, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the whole test set and getting metrics\n",
    "MAE_, R2_, EN_MAE_, ESR_, inference_time = avg_metrics_on_predictions(k_fold=dry_test.shape[0], randomized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Results into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_path = os.path.join('dataset', 'experiments')\n",
    "\n",
    "sf.write(os.path.join(experiments_path, model_name_save + genre +'.wav'), testfile, sr)\n",
    "sf.write(os.path.join(experiments_path, genre +  str(index) + '.wav'), original_wet, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(experiments_path, 'experiments-'+ genre + '.csv') \n",
    "\n",
    "if (os.path.isfile(csv_path)):\n",
    "    dataset = pd.read_csv(csv_path, header=None)\n",
    "else:\n",
    "    dataset = pd.DataFrame(columns=[\n",
    "        'Model Name', 'Effect', 'Frame', 'Sequential Input', 'Training Dataset', \n",
    "        'Hidden Units', 'Batch Size', 'Epochs', 'MAE', 'R2', 'Inference Time',\n",
    "        'EN MAE'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a row to the dataframe\n",
    "s_row = pd.Series([\n",
    "    model_name_save,genre,frame,sequential_input,training_dataset_, hidden_units, \n",
    "    batch_size_para, epochs_, MAE_, R2_, inference_time, EN_MAE_\n",
    "], index=dataset.columns)\n",
    " \n",
    "# Append the above pandas Series object as a row to the existing pandas DataFrame\n",
    "dataset.loc[len(dataset)] = s_row\n",
    "\n",
    "# Displaying the dataframe\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the updated dataframe back to the csv file.\n",
    "if (os.path.isfile(csv_path)):\n",
    "    dataset.to_csv(csv_path, header=False, index=False)\n",
    "else:\n",
    "    dataset.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data for Demoing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pentatonic scale for demo\n",
    "# Keep running till first 5 seconds sound decent\n",
    "clean, effect = data.create_data(genre, effect_data_path, file_data_path, mu_comp=mu_law, srate=sr, \n",
    "                               duration=15, type=\"pentatonic\")\n",
    "length = (int) (len(clean) / frame)\n",
    "\n",
    "ipd.display(ipd.Audio(clean, rate=sr))\n",
    "clean_test, effect_test, _, _, _, _ = create_dataset(clean, effect, 0, length, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict audio with model and save files for later use\n",
    "prepared_audio = prepare_audio_seq(clean_test, index=0)\n",
    "predicted = model.predict(prepared_audio)\n",
    "predicted = predicted.flatten()\n",
    "\n",
    "ipd.display(ipd.Audio(predicted, rate=sr))\n",
    "ipd.display(ipd.Audio(effect_test[0], rate=sr))\n",
    "\n",
    "sf.write(os.path.join(experiments_path, 'Predicted_Demo.wav'), predicted, sr)\n",
    "sf.write(os.path.join(experiments_path, 'Effect_Demo.wav'), effect_test[0], sr)\n",
    "sf.write(os.path.join(experiments_path, 'Clean_Demo.wav'), clean_test[0], sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model on Audio Recorded by Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in files we made as to test\n",
    "def predict_whole_audio(model, audio_file):\n",
    "    audio, _ = librosa.load(os.path.join(experiments_path, audio_file))\n",
    "    audio_length = (int) (len(audio) / frame)\n",
    "    audio_test, _, _, _, _, _ = create_dataset(audio, audio, 0, audio_length, frame, test_ratio=1.0)\n",
    "\n",
    "    predicted_whole = []\n",
    "\n",
    "    for i in range(audio_test.shape[0]):\n",
    "        prepared_audio = prepare_audio_seq(audio_test, index=i)\n",
    "        predicted = model.predict(prepared_audio)\n",
    "        predicted = predicted.flatten()\n",
    "        predicted_whole = np.hstack([predicted_whole, predicted])\n",
    "\n",
    "    return audio, predicted_whole\n",
    "\n",
    "print(\"Predicting Mono1\")\n",
    "mono1, mono1_predicted = predict_whole_audio(model, 'mono1.wav')\n",
    "\n",
    "print(\"Predicting Mono2\")\n",
    "mono2, mono2_predicted = predict_whole_audio(model, 'mono2.wav')\n",
    "\n",
    "print(\"Predicting Poly\")\n",
    "poly, poly_predicted = predict_whole_audio(model, 'poly.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mono1 File\")\n",
    "ipd.display(ipd.Audio(mono1, rate=sr))\n",
    "ipd.display(ipd.Audio(mono1_predicted, rate=sr))\n",
    "\n",
    "print(\"Mono2 File\")\n",
    "ipd.display(ipd.Audio(mono2, rate=sr))\n",
    "ipd.display(ipd.Audio(mono2_predicted, rate=sr))\n",
    "\n",
    "print(\"Poly File\")\n",
    "ipd.display(ipd.Audio(poly, rate=sr))\n",
    "ipd.display(ipd.Audio(poly_predicted, rate=sr))\n",
    "\n",
    "sf.write(os.path.join(experiments_path, 'mono1_predicted.wav'), mono1_predicted, sr)\n",
    "sf.write(os.path.join(experiments_path, 'mono2_predicted.wav'), mono2_predicted, sr)\n",
    "sf.write(os.path.join(experiments_path, 'poly_predicted.wav'), poly_predicted, sr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "446f2e837f7725be6334aa8de739a626b7e93b99618fed198ab63865836f8ce5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
