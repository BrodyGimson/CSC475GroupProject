{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import soundfile as sf\n",
    "import time\n",
    "import random\n",
    "\n",
    "import data\n",
    "import model_utils\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameters\n",
    "sr = 22050\n",
    "\n",
    "# Choose which genre to model\n",
    "genre = \"Metal\"\n",
    "\n",
    "# Size of frame (in samples) that is fed to the model during training\n",
    "frame = 64\n",
    "\n",
    "# Chunk == sample\n",
    "chunk = 1\n",
    "\n",
    "# Duration of data in seconds\n",
    "duration = 30\n",
    "\n",
    "# Model name for saving the model\n",
    "model_name_save = 'csc475_gan_baseline'\n",
    "\n",
    "# Use saved data in dataset/experiments folder\n",
    "use_saved_data = False\n",
    "\n",
    "# Type of input; sequential or random frame order\n",
    "sequential_input = False\n",
    "\n",
    "if sequential_input==True:\n",
    "    shuffle_state = False\n",
    "elif sequential_input==False:\n",
    "    shuffle_state = True\n",
    "\n",
    "# Ratio of test data to training data\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Use mu law companding\n",
    "mu_law=False\n",
    "\n",
    "# Batch size for training\n",
    "batch_size_para = 64\n",
    "\n",
    "# Epochs during training\n",
    "epochs_ = 25\n",
    "\n",
    "# Choose which test file segment to inspect visually\n",
    "# Between 0 and 5 for default 2 minute duration\n",
    "index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling GPU for Mac M1 chips running tensorflow metal, do not use if not on Mac with M1 chip. \n",
    "# (RNNs run slowly on GPU)\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataset\n",
    "file_data_path = os.path.join(\"dataset\", \"fileData.csv\")\n",
    "effect_data_path = os.path.join(\"dataset\", \"effectData.csv\")\n",
    "\n",
    "# Loading the dry and wet audio\n",
    "clean_audio_path = os.path.join(\"dataset\", \"experiments\", \"clean_data.wav\")\n",
    "effect_audio_path = os.path.join(\"dataset\", \"experiments\", \"effect_data.wav\")\n",
    "\n",
    "if (use_saved_data == False):\n",
    "    signal, wet = data.create_data(genre, effect_data_path, file_data_path, mu_comp=mu_law, srate=sr, \n",
    "                                   duration=duration, type=\"random\")\n",
    "    scipy.io.wavfile.write(clean_audio_path, rate=sr, data=signal)\n",
    "    scipy.io.wavfile.write(effect_audio_path, rate=sr, data=wet)\n",
    "else:\n",
    "    signal, _ = librosa.load(clean_audio_path, sr=sr)\n",
    "    wet, _ = librosa.load(effect_audio_path, sr=sr)\n",
    "    \n",
    "\n",
    "# Size of frames in training dataset\n",
    "training_dataset_ = (int) ((len(signal) / frame) * (1 - test_ratio))\n",
    "\n",
    "# Size of frames for testing (not the proper testset, details below)\n",
    "testing_dataset_ = (int) ((len(signal) / frame) * test_ratio)\n",
    "\n",
    "# Whether to filter the audio\n",
    "filtered = False\n",
    "\n",
    "# Creating a high pass filter\n",
    "numtaps = 91\n",
    "cutoff = 0.015\n",
    "b = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='highpass')\n",
    "\n",
    "# Creating a lowpass filter\n",
    "numtaps = 41\n",
    "cutoff = 0.92\n",
    "\n",
    "b2 = scipy.signal.firwin(numtaps, cutoff, width=None, window='hamming', pass_zero='lowpass')\n",
    "\n",
    "# Optionally high pass audio to emphasize high frequency information, low pass to avoid aliasing artifacts\n",
    "if filtered is True:\n",
    "    # High Pass Filter\n",
    "    signal = scipy.signal.lfilter(b, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b, 1, wet)\n",
    "    # Low Pass Filter\n",
    "    signal = scipy.signal.lfilter(b2, 1, signal)\n",
    "    wet = scipy.signal.lfilter(b2, 1, wet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Comparing the original dry audio to the wet audio as a reference' )\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(signal, wet))\n",
    "print('Mean squared error: %.4f'% metrics.mean_squared_error(signal, wet))\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(signal, wet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = (int) (len(signal) * (1 - test_ratio))\n",
    "test_length = (int) (len(signal) * test_ratio)\n",
    "\n",
    "features_train = signal[0:train_length]\n",
    "features_test = signal[train_length:train_length + test_length]\n",
    "\n",
    "targets_train = wet[0:train_length]\n",
    "targets_test = wet[train_length:train_length + test_length]\n",
    "\n",
    "length_in_seconds = features_train.size / sr\n",
    "length_for_wet = targets_train.size / sr\n",
    "print('Length of training dry audio is {} seconds'.format(length_in_seconds)) \n",
    "print('Length of training wet audio is {} seconds'.format(length_for_wet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAN architecture\n",
    "class Generator(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(frame * chunk, activation='tanh')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "class Discriminator(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "# Initialize generator, discriminator, and GAN\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "model = tf.keras.Sequential([generator, discriminator], name=model_name_save)\n",
    "\n",
    "# Define loss functions\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "def generate_noise(batch_size, noise_dim):\n",
    "    return tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "@tf.function\n",
    "def train_step(audio, effects):\n",
    "    noise = generate_noise(tf.shape(audio)[0], noise_dim)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_audio = generator(tf.concat([noise, effects], axis=1), training=True)\n",
    "\n",
    "        real_output = discriminator(tf.concat([audio, effects], axis=1), training=True)\n",
    "        fake_output = discriminator(tf.concat([generated_audio, effects], axis=1), training=True)\n",
    "\n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        disc_loss_real = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        disc_loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n",
    "\n",
    "# Define function to apply effect to audio\n",
    "def apply_effect(audio, batch_size):\n",
    "    noise = generate_noise(1, noise_dim)\n",
    "    generated_audio = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(0, len(audio), batch_size):\n",
    "        batch_audio = []\n",
    "        \n",
    "        if (audio[i:i+batch_size].size == batch_size):\n",
    "            batch_audio.append(audio[i:i+batch_size])\n",
    "            generated_batch = generator(tf.concat([noise,batch_audio], axis=1), training=False)\n",
    "            \n",
    "            generated_audio = np.hstack([generated_audio, generated_batch[0]])\n",
    "            counter += 1\n",
    "            print('Batch {} / {}'.format(counter, (int) (len(audio) / batch_size)), end='\\r')\n",
    "    return generated_audio\n",
    "\n",
    "# train GAN\n",
    "def train_gan(audio, effects, epochs, batch_size):\n",
    "    gen_loss = 0\n",
    "    disc_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}'.format(epoch + 1))\n",
    "        start = time.time()\n",
    "        counter = 0\n",
    "        \n",
    "        for i in range(0, len(audio), batch_size):\n",
    "            batch_audio = []\n",
    "            batch_effects = []\n",
    "            \n",
    "            if (audio[i:i+batch_size].size == batch_size and effects[i:i+batch_size].size == batch_size):\n",
    "                batch_audio.append(audio[i:i+batch_size])\n",
    "                batch_effects.append(effects[i:i+batch_size])\n",
    "\n",
    "                gen_loss, disc_loss = train_step(batch_audio, batch_effects)\n",
    "                counter += 1\n",
    "                print('Batch %d / %d' % (counter, (int) (len(audio) / batch_size)), end='\\r')\n",
    "                \n",
    "                \n",
    "        print ('Time for epoch %d is %.4f sec, generator loss %.4f, discriminator loss %.4f' % (\n",
    "            epoch + 1, time.time()-start, gen_loss, disc_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gan(features_train, targets_train, epochs=epochs_, batch_size=batch_size_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_pred = apply_effect(features_test, batch_size_para)\n",
    "train_tar_pred = apply_effect(features_train, batch_size_para)\n",
    "\n",
    "# Mean squared error (lower the better)\n",
    "print('Mean squared error: {}'.format(metrics.mean_squared_error(targets_test[:len(tar_pred)], tar_pred)))\n",
    "\n",
    "# Mean absolute error (lower the better)\n",
    "print('Mean absolute error: %.4f'% metrics.mean_absolute_error(targets_test[:len(tar_pred)], tar_pred))\n",
    "\n",
    "# Median absolute error (lower the better)\n",
    "print('Median absolute error: %.4f'% metrics.median_absolute_error(targets_test[:len(tar_pred)], tar_pred))\n",
    "\n",
    "# Coefficient of determination (r2 score): 1 is perfect prediction (it can get arbitrary negative)\n",
    "print('Coefficient of determination (R2 score): %.4f'% metrics.r2_score(targets_test[:len(tar_pred)], tar_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction (it can get arbitrary worse)\n",
    "print('Explained variance score: %.4f'% metrics.explained_variance_score(targets_test[:len(tar_pred)], tar_pred))\n",
    "    \n",
    "model_utils.plot_result(targets_train[:len(train_tar_pred)], targets_test[:len(tar_pred)], train_tar_pred, tar_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model (ignore warnings)\n",
    "model.save(os.path.join('dataset', 'models',model_name_save + '.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "## Work in Progress\n",
    "Not complete."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "446f2e837f7725be6334aa8de739a626b7e93b99618fed198ab63865836f8ce5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
