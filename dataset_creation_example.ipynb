{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e018bc56-d6f7-4b3a-b77b-df5ab824f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import data\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lib\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5017209",
   "metadata": {},
   "source": [
    "# Dataset Creation Example\n",
    "This notebook is used to give examples of using the dataset creation tools included in this repo. The LSTM model requires input and output data to be a few minutes of audio for training. The IDMT-SFT-Audio-Effects used has the effects as single notes that last a few seconds. The dataset creation tools combine these notes to create longer audio to meet the requirements of the LSTM. The functions create both clean and audio with effects at the same time to ensure they contain the same notes and durations.\n",
    "\n",
    "## Loading Data with Librosa\n",
    "To start, we look at some methods Librosa has to make training the model easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c61646-dc71-44e7-af81-a2f86a4abf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sample Length: 44101\n",
      "Original Sample Rate: 22050\n",
      "\n",
      "Downsampled Sample Length: 8001\n",
      "Downsampled Sample Rate: 4000\n",
      "\n",
      "Original: 0.203066\n",
      "Mu Compressed: 91\n",
      "Mu Expanded: 0.198179\n"
     ]
    }
   ],
   "source": [
    "# Edit to change folder paths\n",
    "mono_sample_path = os.path.join(\"dataset\", \"monophonic\", \"Samples\")\n",
    "\n",
    "# Loading sound at its sampling rate\n",
    "audio, srate = lib.load(os.path.join(mono_sample_path, \"Distortion\", \"G61-41101-4412-38066.wav\"))\n",
    "print(\"Original Sample Length: %d\" % audio.shape[0])\n",
    "print(\"Original Sample Rate: %d\" % srate)\n",
    "# Uncomment to hear\n",
    "# ipd.display(ipd.Audio(audio, rate=srate))\n",
    "\n",
    "# Loading sound at a lower sampling rate\n",
    "# Lower sampling rate means less points of data, making training faster at the expense of quality\n",
    "ds_audio, ds_srate = lib.load(os.path.join(mono_sample_path, \"Distortion\", \"G61-41101-4412-38066.wav\"), sr=4000)\n",
    "print(\"\\nDownsampled Sample Length: %d\" % ds_audio.shape[0])\n",
    "print(\"Downsampled Sample Rate: %d\" % ds_srate)\n",
    "# Uncomment to hear\n",
    "# ipd.display(ipd.Audio(ds_audio, rate=ds_srate))\n",
    "\n",
    "# Mu's law quantizes the output range\n",
    "# This greatly decreases the range of values the model has to predict down to only 256 values\n",
    "# Once the prediction is made, the values can be decompressed which will have some info loss\n",
    "comp_ds_audio = lib.mu_compress(ds_audio, mu=255)\n",
    "decomp_ds_audio = lib.mu_expand(comp_ds_audio, mu=255)\n",
    "print(\"\\nOriginal: %f\" % max(ds_audio))\n",
    "print(\"Mu Compressed: %d\" % max(comp_ds_audio))\n",
    "print(\"Mu Expanded: %f\" % max(decomp_ds_audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69a065",
   "metadata": {},
   "source": [
    "## Basic Dataset Creation\n",
    "The dataset creation tool has a few options to make the training audio different. These choices include a simple scale of the available notes, a random tune made from all notes, or a random tune made from a pentatonic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8759db6b-8e57-4591-a0d2-c0612ad55624",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_audio, effect_audio = data.create_data(\"Distortion\", \"metadata,csv\", mu_comp=False)\n",
    "\n",
    "print(\"Clean Audio:\")\n",
    "ipd.display(ipd.Audio(clean_audio, rate=22050))\n",
    "print(\"\\nDistortion Audio:\")\n",
    "ipd.display(ipd.Audio(effect_audio, rate=22050))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a0e0d",
   "metadata": {},
   "source": [
    "The tool also allows specifying whether to use mu's law or not. By default it is turned on, as seen above it can be turned off. This allows for easy experimentation to see what performs better. The sampling rate can also be specified by passing an srate parameter. By default it uses the datasets rate of 22050 Hz. The duration can also be specified in seconds, with a default of 120s (i.e. 2 minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c210712",
   "metadata": {},
   "source": [
    "Below are examples of the other data creation types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_audio, effect_audio = data.create_data(\"Distortion\", \"metadata,csv\", mu_comp=False, type=\"random\")\n",
    "\n",
    "print(\"Clean Random Audio:\")\n",
    "ipd.display(ipd.Audio(clean_audio, rate=22050))\n",
    "print(\"\\nDistortion Random Audio:\")\n",
    "ipd.display(ipd.Audio(effect_audio, rate=22050))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
